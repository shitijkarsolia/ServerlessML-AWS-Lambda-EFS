{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker Data-Processing & Training Job\n",
    "\n",
    "With Amazon SageMaker, you can leverage a simplified, managed experience to run data pre- or post-processing and model evaluation workloads on the Amazon SageMaker platform.\n",
    "\n",
    "A processing job downloads input from Amazon Simple Storage Service (Amazon S3), then uploads outputs to Amazon S3 during or after the processing job.\n",
    "\n",
    "This notebook shows how you can:\n",
    "\n",
    "1. Run a processing job to run a scikit-learn script that cleans, pre-processes, performs feature engineering, and splits the input data into train and test sets.\n",
    "2. Run a training job on the pre-processed training data to train a model\n",
    "3. Predict on the trained model\n",
    "\n",
    "The dataset used here is the [Census-Income KDD Dataset](https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29). You select features from this dataset, clean the data, and turn the data into features that the training algorithm can use to train a binary classification model, and split the data into train and test sets. The task is to predict whether rows representing census responders have an income greater than `$50,000`, or less than `$50,000` by training a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mounting the EFS filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('efs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.0.2.136'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_addr = client.describe_mount_targets(FileSystemId='fs-7b1a6df8')['MountTargets'][0]['IpAddress']\n",
    "ip_addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mount.nfs: /home/ec2-user/SageMaker/repo_efs/efs_lambda/efs is busy or already mounted\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "mkdir efs\n",
    "sudo mount -t nfs \\\n",
    "    -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 \\\n",
    "    10.0.2.136:/ \\\n",
    "    ./efs\n",
    "\n",
    "sudo chmod go+rw ./efs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the scikit-learn preprocessing script as a processing job, create a `SKLearnProcessor`, which lets you run scripts inside of processing jobs using the scikit-learn image provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available kernels:\r\n",
      "  ir         /home/ec2-user/.local/share/jupyter/kernels/ir\r\n",
      "  python3    /home/ec2-user/anaconda3/envs/python3/share/jupyter/kernels/python3\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==0.25.3\n",
      "  Downloading pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4 MB 17.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas==0.25.3) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas==0.25.3) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas==0.25.3) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas==0.25.3) (1.14.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.0.3\n",
      "    Uninstalling pandas-1.0.3:\n",
      "      Successfully uninstalled pandas-1.0.3\n",
      "Successfully installed pandas-0.25.3\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting scikit-learn==0.21.3\n",
      "  Downloading scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7 MB 15.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn==0.21.3) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn==0.21.3) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn==0.21.3) (1.18.1)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "Successfully installed scikit-learn-0.21.3\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas==0.25.3 \n",
    "!pip install scikit-learn==0.21.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.m5.xlarge',\n",
    "                                     instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before introducing the script you use for data cleaning, pre-processing, and feature engineering, inspect the first 20 rows of the dataset. The target is predicting the `income` category. The features from the dataset you select are `age`, `education`, `major industry code`, `class of worker`, `num persons worked for employer`, `capital gains`, `capital losses`, and `dividends from stocks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>class of worker</th>\n",
       "      <th>detailed industry recode</th>\n",
       "      <th>detailed occupation recode</th>\n",
       "      <th>education</th>\n",
       "      <th>wage per hour</th>\n",
       "      <th>enroll in edu inst last wk</th>\n",
       "      <th>marital stat</th>\n",
       "      <th>major industry code</th>\n",
       "      <th>major occupation code</th>\n",
       "      <th>...</th>\n",
       "      <th>country of birth father</th>\n",
       "      <th>country of birth mother</th>\n",
       "      <th>country of birth self</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>own business or self employed</th>\n",
       "      <th>fill inc questionnaire for veteran's admin</th>\n",
       "      <th>veterans benefits</th>\n",
       "      <th>weeks worked in year</th>\n",
       "      <th>year</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>Self-employed-not incorporated</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Precision production craft &amp; repair</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10th grade</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Foreign born- Not a citizen of U S</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Children</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Children</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48</td>\n",
       "      <td>Private</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>1200</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Professional specialty</td>\n",
       "      <td>...</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>2</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>Bachelors degree(BA AB BS)</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Finance insurance and real estate</td>\n",
       "      <td>Executive admin and managerial</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Handlers equip cleaners etc</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47</td>\n",
       "      <td>Local government</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>876</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Education</td>\n",
       "      <td>Adm support including clerical</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Machine operators assmblrs &amp; inspctrs</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                  class of worker  detailed industry recode  \\\n",
       "0   73                  Not in universe                         0   \n",
       "1   58   Self-employed-not incorporated                         4   \n",
       "2   18                  Not in universe                         0   \n",
       "3    9                  Not in universe                         0   \n",
       "4   10                  Not in universe                         0   \n",
       "5   48                          Private                        40   \n",
       "6   42                          Private                        34   \n",
       "7   28                          Private                         4   \n",
       "8   47                 Local government                        43   \n",
       "9   34                          Private                         4   \n",
       "\n",
       "   detailed occupation recode                    education  wage per hour  \\\n",
       "0                           0         High school graduate              0   \n",
       "1                          34   Some college but no degree              0   \n",
       "2                           0                   10th grade              0   \n",
       "3                           0                     Children              0   \n",
       "4                           0                     Children              0   \n",
       "5                          10   Some college but no degree           1200   \n",
       "6                           3   Bachelors degree(BA AB BS)              0   \n",
       "7                          40         High school graduate              0   \n",
       "8                          26   Some college but no degree            876   \n",
       "9                          37   Some college but no degree              0   \n",
       "\n",
       "  enroll in edu inst last wk                      marital stat  \\\n",
       "0            Not in universe                           Widowed   \n",
       "1            Not in universe                          Divorced   \n",
       "2                High school                     Never married   \n",
       "3            Not in universe                     Never married   \n",
       "4            Not in universe                     Never married   \n",
       "5            Not in universe   Married-civilian spouse present   \n",
       "6            Not in universe   Married-civilian spouse present   \n",
       "7            Not in universe                     Never married   \n",
       "8            Not in universe   Married-civilian spouse present   \n",
       "9            Not in universe   Married-civilian spouse present   \n",
       "\n",
       "                  major industry code                   major occupation code  \\\n",
       "0         Not in universe or children                         Not in universe   \n",
       "1                        Construction     Precision production craft & repair   \n",
       "2         Not in universe or children                         Not in universe   \n",
       "3         Not in universe or children                         Not in universe   \n",
       "4         Not in universe or children                         Not in universe   \n",
       "5                       Entertainment                  Professional specialty   \n",
       "6   Finance insurance and real estate          Executive admin and managerial   \n",
       "7                        Construction            Handlers equip cleaners etc    \n",
       "8                           Education          Adm support including clerical   \n",
       "9                        Construction   Machine operators assmblrs & inspctrs   \n",
       "\n",
       "   ... country of birth father country of birth mother country of birth self  \\\n",
       "0  ...           United-States           United-States         United-States   \n",
       "1  ...           United-States           United-States         United-States   \n",
       "2  ...                 Vietnam                 Vietnam               Vietnam   \n",
       "3  ...           United-States           United-States         United-States   \n",
       "4  ...           United-States           United-States         United-States   \n",
       "5  ...             Philippines           United-States         United-States   \n",
       "6  ...           United-States           United-States         United-States   \n",
       "7  ...           United-States           United-States         United-States   \n",
       "8  ...           United-States           United-States         United-States   \n",
       "9  ...           United-States           United-States         United-States   \n",
       "\n",
       "                            citizenship own business or self employed  \\\n",
       "0     Native- Born in the United States                             0   \n",
       "1     Native- Born in the United States                             0   \n",
       "2   Foreign born- Not a citizen of U S                              0   \n",
       "3     Native- Born in the United States                             0   \n",
       "4     Native- Born in the United States                             0   \n",
       "5     Native- Born in the United States                             2   \n",
       "6     Native- Born in the United States                             0   \n",
       "7     Native- Born in the United States                             0   \n",
       "8     Native- Born in the United States                             0   \n",
       "9     Native- Born in the United States                             0   \n",
       "\n",
       "  fill inc questionnaire for veteran's admin  veterans benefits  \\\n",
       "0                            Not in universe                  2   \n",
       "1                            Not in universe                  2   \n",
       "2                            Not in universe                  2   \n",
       "3                            Not in universe                  0   \n",
       "4                            Not in universe                  0   \n",
       "5                            Not in universe                  2   \n",
       "6                            Not in universe                  2   \n",
       "7                            Not in universe                  2   \n",
       "8                            Not in universe                  2   \n",
       "9                            Not in universe                  2   \n",
       "\n",
       "   weeks worked in year  year     income  \n",
       "0                     0    95   - 50000.  \n",
       "1                    52    94   - 50000.  \n",
       "2                     0    95   - 50000.  \n",
       "3                     0    94   - 50000.  \n",
       "4                     0    94   - 50000.  \n",
       "5                    52    95   - 50000.  \n",
       "6                    52    94   - 50000.  \n",
       "7                    30    95   - 50000.  \n",
       "8                    52    95   - 50000.  \n",
       "9                    52    94   - 50000.  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_data = 's3://sagemaker-sample-data-{}/processing/census/census-income.csv'.format(region)\n",
    "df = pd.read_csv(input_data, nrows=10)\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook cell writes a file `preprocessing.py`, which contains the pre-processing script. You can update the script, and rerun this cell to overwrite `preprocessing.py`. You run this as a processing job in the next cell. In this script, you\n",
    "\n",
    "* Remove duplicates and rows with conflicting data\n",
    "* transform the target `income` column into a column containing two labels.\n",
    "* transform the `age` and `num persons worked for employer` numerical columns into categorical features by binning them\n",
    "* scale the continuous `capital gains`, `capital losses`, and `dividends from stocks` so they're suitable for training\n",
    "* encode the `education`, `major industry code`, `class of worker` so they're suitable for training\n",
    "* split the data into training and test datasets, and saves the training features and labels and test features and labels.\n",
    "\n",
    "Our training script will use the pre-processed training features and labels to train a model, and our model evaluation script will use the trained model and pre-processed test features and labels to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer, KBinsDiscretizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.compose import make_column_transformer\n",
    "from pickle import dump\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "\n",
    "columns = ['age', 'education', 'major industry code', 'class of worker', 'num persons worked for employer',\n",
    "           'capital gains', 'capital losses', 'dividends from stocks', 'income']\n",
    "class_labels = [' - 50000.', ' 50000+.']\n",
    "\n",
    "def print_shape(df):\n",
    "    negative_examples, positive_examples = np.bincount(df['income'])\n",
    "    print('Data shape: {}, {} positive examples, {} negative examples'.format(df.shape, positive_examples, negative_examples))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train-test-split-ratio', type=float, default=0.3)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print('Received arguments {}'.format(args))\n",
    "\n",
    "    input_data_path = os.path.join('/opt/ml/processing/input', 'census-income.csv')\n",
    "    \n",
    "    print('Reading input data from {}'.format(input_data_path))\n",
    "    df = pd.read_csv(input_data_path)\n",
    "    df = pd.DataFrame(data=df, columns=columns)\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.replace(class_labels, [0, 1], inplace=True)\n",
    "    \n",
    "    negative_examples, positive_examples = np.bincount(df['income'])\n",
    "    print('Data after cleaning: {}, {} positive examples, {} negative examples'.format(df.shape, positive_examples, negative_examples))\n",
    "    \n",
    "    split_ratio = args.train_test_split_ratio\n",
    "    print('Splitting data into train and test sets with ratio {}'.format(split_ratio))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop('income', axis=1), df['income'], test_size=split_ratio, random_state=0)\n",
    "\n",
    "    preprocess = make_column_transformer(\n",
    "        (['age', 'num persons worked for employer'], KBinsDiscretizer(encode='onehot-dense', n_bins=10)),\n",
    "        (['capital gains', 'capital losses', 'dividends from stocks'], StandardScaler()),\n",
    "        (['education', 'major industry code', 'class of worker'], OneHotEncoder(sparse=False))\n",
    "    )\n",
    "    print('Running preprocessing and feature engineering transformations')\n",
    "    train_features = preprocess.fit_transform(X_train)\n",
    "    test_features = preprocess.transform(X_test)\n",
    "    \n",
    "    print('Train data shape after preprocessing: {}'.format(train_features.shape))\n",
    "    print('Test data shape after preprocessing: {}'.format(test_features.shape))\n",
    "    \n",
    "    train_features_output_path = os.path.join('/opt/ml/processing/train', 'train_features.csv')\n",
    "    train_labels_output_path = os.path.join('/opt/ml/processing/train', 'train_labels.csv')\n",
    "    \n",
    "    test_features_output_path = os.path.join('/opt/ml/processing/test', 'test_features.csv')\n",
    "    test_labels_output_path = os.path.join('/opt/ml/processing/test', 'test_labels.csv')\n",
    "    \n",
    "    print('Saving training features to {}'.format(train_features_output_path))\n",
    "    pd.DataFrame(train_features).to_csv(train_features_output_path, header=False, index=False)\n",
    "    \n",
    "    print('Saving test features to {}'.format(test_features_output_path))\n",
    "    pd.DataFrame(test_features).to_csv(test_features_output_path, header=False, index=False)\n",
    "    \n",
    "    print('Saving training labels to {}'.format(train_labels_output_path))\n",
    "    y_train.to_csv(train_labels_output_path, header=False, index=False)\n",
    "    \n",
    "    print('Saving test labels to {}'.format(test_labels_output_path))\n",
    "    y_test.to_csv(test_labels_output_path, header=False, index=False)\n",
    "    \n",
    "    dump(preprocess, open('/opt/ml/processing/processor/preprocessor.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this script as a processing job. Use the `SKLearnProcessor.run()` method. You give the `run()` method one `ProcessingInput` where the `source` is the census dataset in Amazon S3, and the `destination` is where the script reads this data from, in this case `/opt/ml/processing/input`. These local paths inside the processing container must begin with `/opt/ml/processing/`.\n",
    "\n",
    "Also give the `run()` method a `ProcessingOutput`, where the `source` is the path the script writes output data to. For outputs, the `destination` defaults to an S3 bucket that the Amazon SageMaker Python SDK creates for you, following the format `s3://sagemaker-<region>-<account_id>/<processing_job_name>/output/<output_name/`. You also give the ProcessingOutputs values for `output_name`, to make it easier to retrieve these output artifacts after the job is run.\n",
    "\n",
    "The `arguments` parameter in the `run()` method are command-line arguments in our `preprocessing.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_processor.run(code='preprocessing.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source=input_data,\n",
    "                        destination='/opt/ml/processing/input')],\n",
    "                      outputs=[ProcessingOutput(output_name='train_data',\n",
    "                                                source='/opt/ml/processing/train'),\n",
    "                               ProcessingOutput(output_name='test_data',\n",
    "                                                source='/opt/ml/processing/test'),\n",
    "                               ProcessingOutput(output_name='saved_processor',\n",
    "                                                source='/opt/ml/processing/processor')],\n",
    "                      arguments=['--train-test-split-ratio', '0.2']\n",
    "                     )\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "\n",
    "output_config = preprocessing_job_description['ProcessingOutputConfig']\n",
    "for output in output_config['Outputs']:\n",
    "    if output['OutputName'] == 'train_data':\n",
    "        preprocessed_training_data = output['S3Output']['S3Uri']\n",
    "    if output['OutputName'] == 'test_data':\n",
    "        preprocessed_test_data = output['S3Output']['S3Uri']\n",
    "    if output['OutputName'] == 'saved_processor':\n",
    "        preprocessor = output['S3Output']['S3Uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 256.0 KiB/99.1 MiB (1.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 512.0 KiB/99.1 MiB (3.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 768.0 KiB/99.1 MiB (4.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 1.0 MiB/99.1 MiB (6.0 MiB/s) with 1 file(s) remaining  \r",
      "Completed 1.2 MiB/99.1 MiB (7.4 MiB/s) with 1 file(s) remaining  \r",
      "Completed 1.5 MiB/99.1 MiB (8.7 MiB/s) with 1 file(s) remaining  \r",
      "Completed 1.8 MiB/99.1 MiB (10.0 MiB/s) with 1 file(s) remaining \r",
      "Completed 2.0 MiB/99.1 MiB (11.4 MiB/s) with 1 file(s) remaining \r",
      "Completed 2.2 MiB/99.1 MiB (12.4 MiB/s) with 1 file(s) remaining \r",
      "Completed 2.5 MiB/99.1 MiB (13.6 MiB/s) with 1 file(s) remaining \r",
      "Completed 2.8 MiB/99.1 MiB (14.7 MiB/s) with 1 file(s) remaining \r",
      "Completed 3.0 MiB/99.1 MiB (15.9 MiB/s) with 1 file(s) remaining \r",
      "Completed 3.2 MiB/99.1 MiB (16.8 MiB/s) with 1 file(s) remaining \r",
      "Completed 3.5 MiB/99.1 MiB (18.0 MiB/s) with 1 file(s) remaining \r",
      "Completed 3.8 MiB/99.1 MiB (18.8 MiB/s) with 1 file(s) remaining \r",
      "Completed 4.0 MiB/99.1 MiB (19.5 MiB/s) with 1 file(s) remaining \r",
      "Completed 4.2 MiB/99.1 MiB (20.6 MiB/s) with 1 file(s) remaining \r",
      "Completed 4.5 MiB/99.1 MiB (21.7 MiB/s) with 1 file(s) remaining \r",
      "Completed 4.8 MiB/99.1 MiB (22.6 MiB/s) with 1 file(s) remaining \r",
      "Completed 5.0 MiB/99.1 MiB (23.5 MiB/s) with 1 file(s) remaining \r",
      "Completed 5.2 MiB/99.1 MiB (24.0 MiB/s) with 1 file(s) remaining \r",
      "Completed 5.5 MiB/99.1 MiB (25.0 MiB/s) with 1 file(s) remaining \r",
      "Completed 5.8 MiB/99.1 MiB (26.1 MiB/s) with 1 file(s) remaining \r",
      "Completed 6.0 MiB/99.1 MiB (26.6 MiB/s) with 1 file(s) remaining \r",
      "Completed 6.2 MiB/99.1 MiB (27.4 MiB/s) with 1 file(s) remaining \r",
      "Completed 6.5 MiB/99.1 MiB (28.4 MiB/s) with 1 file(s) remaining \r",
      "Completed 6.8 MiB/99.1 MiB (29.1 MiB/s) with 1 file(s) remaining \r",
      "Completed 7.0 MiB/99.1 MiB (29.9 MiB/s) with 1 file(s) remaining \r",
      "Completed 7.2 MiB/99.1 MiB (30.8 MiB/s) with 1 file(s) remaining \r",
      "Completed 7.5 MiB/99.1 MiB (31.4 MiB/s) with 1 file(s) remaining \r",
      "Completed 7.8 MiB/99.1 MiB (32.2 MiB/s) with 1 file(s) remaining \r",
      "Completed 8.0 MiB/99.1 MiB (32.9 MiB/s) with 1 file(s) remaining \r",
      "Completed 8.2 MiB/99.1 MiB (33.5 MiB/s) with 1 file(s) remaining \r",
      "Completed 8.5 MiB/99.1 MiB (34.1 MiB/s) with 1 file(s) remaining \r",
      "Completed 8.8 MiB/99.1 MiB (34.8 MiB/s) with 1 file(s) remaining \r",
      "Completed 9.0 MiB/99.1 MiB (35.5 MiB/s) with 1 file(s) remaining \r",
      "Completed 9.2 MiB/99.1 MiB (36.4 MiB/s) with 1 file(s) remaining \r",
      "Completed 9.5 MiB/99.1 MiB (37.2 MiB/s) with 1 file(s) remaining \r",
      "Completed 9.8 MiB/99.1 MiB (38.0 MiB/s) with 1 file(s) remaining \r",
      "Completed 10.0 MiB/99.1 MiB (38.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 10.2 MiB/99.1 MiB (39.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 10.5 MiB/99.1 MiB (39.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 10.8 MiB/99.1 MiB (40.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 11.0 MiB/99.1 MiB (40.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 11.2 MiB/99.1 MiB (41.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 11.5 MiB/99.1 MiB (42.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 11.8 MiB/99.1 MiB (43.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 12.0 MiB/99.1 MiB (43.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 12.2 MiB/99.1 MiB (43.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 12.5 MiB/99.1 MiB (44.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 12.8 MiB/99.1 MiB (44.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 13.0 MiB/99.1 MiB (45.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 13.2 MiB/99.1 MiB (46.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 13.5 MiB/99.1 MiB (46.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 13.8 MiB/99.1 MiB (47.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 14.0 MiB/99.1 MiB (47.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 14.2 MiB/99.1 MiB (47.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 14.5 MiB/99.1 MiB (47.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 14.8 MiB/99.1 MiB (48.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 15.0 MiB/99.1 MiB (49.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 15.2 MiB/99.1 MiB (49.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 15.5 MiB/99.1 MiB (50.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 15.8 MiB/99.1 MiB (51.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 16.0 MiB/99.1 MiB (50.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 16.2 MiB/99.1 MiB (50.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 16.5 MiB/99.1 MiB (51.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 16.8 MiB/99.1 MiB (52.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 17.0 MiB/99.1 MiB (52.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 17.2 MiB/99.1 MiB (53.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 17.5 MiB/99.1 MiB (53.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 17.8 MiB/99.1 MiB (54.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 18.0 MiB/99.1 MiB (55.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 18.2 MiB/99.1 MiB (55.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 18.5 MiB/99.1 MiB (55.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 18.8 MiB/99.1 MiB (55.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 19.0 MiB/99.1 MiB (56.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 19.2 MiB/99.1 MiB (56.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 19.5 MiB/99.1 MiB (57.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 19.8 MiB/99.1 MiB (57.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 20.0 MiB/99.1 MiB (57.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 20.2 MiB/99.1 MiB (58.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 20.5 MiB/99.1 MiB (58.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 20.8 MiB/99.1 MiB (58.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 21.0 MiB/99.1 MiB (59.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 21.2 MiB/99.1 MiB (59.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 21.5 MiB/99.1 MiB (60.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 21.8 MiB/99.1 MiB (59.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 22.0 MiB/99.1 MiB (60.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 22.2 MiB/99.1 MiB (60.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 22.5 MiB/99.1 MiB (60.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 22.8 MiB/99.1 MiB (61.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 23.0 MiB/99.1 MiB (62.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 23.2 MiB/99.1 MiB (62.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 23.5 MiB/99.1 MiB (62.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 23.8 MiB/99.1 MiB (62.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 24.0 MiB/99.1 MiB (62.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 24.2 MiB/99.1 MiB (63.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 24.5 MiB/99.1 MiB (63.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 24.8 MiB/99.1 MiB (64.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 25.0 MiB/99.1 MiB (64.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 25.2 MiB/99.1 MiB (65.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 25.5 MiB/99.1 MiB (64.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 25.8 MiB/99.1 MiB (64.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 26.0 MiB/99.1 MiB (64.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 26.2 MiB/99.1 MiB (64.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 26.5 MiB/99.1 MiB (65.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 26.8 MiB/99.1 MiB (65.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 27.0 MiB/99.1 MiB (65.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 27.2 MiB/99.1 MiB (66.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 27.5 MiB/99.1 MiB (66.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 27.8 MiB/99.1 MiB (65.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 28.0 MiB/99.1 MiB (66.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 28.2 MiB/99.1 MiB (66.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 28.5 MiB/99.1 MiB (66.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 28.8 MiB/99.1 MiB (67.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 29.0 MiB/99.1 MiB (67.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 29.2 MiB/99.1 MiB (68.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 29.5 MiB/99.1 MiB (68.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 29.8 MiB/99.1 MiB (69.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 30.0 MiB/99.1 MiB (69.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 30.2 MiB/99.1 MiB (69.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 30.5 MiB/99.1 MiB (68.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 30.8 MiB/99.1 MiB (68.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 31.0 MiB/99.1 MiB (69.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 31.2 MiB/99.1 MiB (69.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 31.5 MiB/99.1 MiB (70.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 31.8 MiB/99.1 MiB (70.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 32.0 MiB/99.1 MiB (70.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 32.2 MiB/99.1 MiB (70.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 32.5 MiB/99.1 MiB (70.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 32.8 MiB/99.1 MiB (70.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 33.0 MiB/99.1 MiB (71.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 33.2 MiB/99.1 MiB (71.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 33.5 MiB/99.1 MiB (71.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 33.8 MiB/99.1 MiB (71.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 34.0 MiB/99.1 MiB (71.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 34.2 MiB/99.1 MiB (71.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 34.5 MiB/99.1 MiB (72.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 34.8 MiB/99.1 MiB (72.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 35.0 MiB/99.1 MiB (73.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 35.2 MiB/99.1 MiB (73.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 35.5 MiB/99.1 MiB (73.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 35.8 MiB/99.1 MiB (73.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 36.0 MiB/99.1 MiB (73.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 36.2 MiB/99.1 MiB (73.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 36.5 MiB/99.1 MiB (73.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 36.8 MiB/99.1 MiB (73.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 37.0 MiB/99.1 MiB (74.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 37.2 MiB/99.1 MiB (74.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 37.5 MiB/99.1 MiB (74.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 37.8 MiB/99.1 MiB (75.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 38.0 MiB/99.1 MiB (74.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 38.2 MiB/99.1 MiB (74.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 38.5 MiB/99.1 MiB (74.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 38.8 MiB/99.1 MiB (75.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 39.0 MiB/99.1 MiB (75.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 39.2 MiB/99.1 MiB (75.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 39.5 MiB/99.1 MiB (76.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 39.8 MiB/99.1 MiB (76.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 40.0 MiB/99.1 MiB (76.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 40.2 MiB/99.1 MiB (77.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 40.5 MiB/99.1 MiB (76.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 40.8 MiB/99.1 MiB (76.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 41.0 MiB/99.1 MiB (77.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 41.2 MiB/99.1 MiB (77.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 41.5 MiB/99.1 MiB (77.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 41.8 MiB/99.1 MiB (77.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 42.0 MiB/99.1 MiB (77.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 42.2 MiB/99.1 MiB (78.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 42.5 MiB/99.1 MiB (77.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 42.8 MiB/99.1 MiB (77.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 43.0 MiB/99.1 MiB (77.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 43.2 MiB/99.1 MiB (78.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 43.5 MiB/99.1 MiB (78.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 43.8 MiB/99.1 MiB (78.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 44.0 MiB/99.1 MiB (78.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 44.2 MiB/99.1 MiB (78.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 44.5 MiB/99.1 MiB (78.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 44.8 MiB/99.1 MiB (78.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 45.0 MiB/99.1 MiB (78.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 45.2 MiB/99.1 MiB (78.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 45.5 MiB/99.1 MiB (78.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 45.8 MiB/99.1 MiB (78.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 46.0 MiB/99.1 MiB (79.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 46.2 MiB/99.1 MiB (79.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 46.5 MiB/99.1 MiB (79.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 46.8 MiB/99.1 MiB (79.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 47.0 MiB/99.1 MiB (79.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 47.2 MiB/99.1 MiB (79.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 47.5 MiB/99.1 MiB (79.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 47.8 MiB/99.1 MiB (79.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 48.0 MiB/99.1 MiB (79.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 48.2 MiB/99.1 MiB (79.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 48.5 MiB/99.1 MiB (80.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 48.8 MiB/99.1 MiB (80.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 49.0 MiB/99.1 MiB (80.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 49.2 MiB/99.1 MiB (80.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 49.5 MiB/99.1 MiB (81.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 49.8 MiB/99.1 MiB (81.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 50.0 MiB/99.1 MiB (80.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 50.2 MiB/99.1 MiB (81.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 50.5 MiB/99.1 MiB (81.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 50.8 MiB/99.1 MiB (81.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 51.0 MiB/99.1 MiB (81.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 51.2 MiB/99.1 MiB (81.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 51.5 MiB/99.1 MiB (82.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 51.8 MiB/99.1 MiB (82.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 52.0 MiB/99.1 MiB (82.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 52.2 MiB/99.1 MiB (82.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 52.5 MiB/99.1 MiB (81.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 52.8 MiB/99.1 MiB (81.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 53.0 MiB/99.1 MiB (82.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 53.2 MiB/99.1 MiB (82.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 53.5 MiB/99.1 MiB (82.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 53.8 MiB/99.1 MiB (83.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 54.0 MiB/99.1 MiB (83.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 54.2 MiB/99.1 MiB (83.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 54.5 MiB/99.1 MiB (83.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 54.8 MiB/99.1 MiB (83.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 55.0 MiB/99.1 MiB (83.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 55.2 MiB/99.1 MiB (83.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 55.5 MiB/99.1 MiB (83.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 55.8 MiB/99.1 MiB (83.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 56.0 MiB/99.1 MiB (83.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 56.2 MiB/99.1 MiB (83.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 56.5 MiB/99.1 MiB (83.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 56.8 MiB/99.1 MiB (84.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 57.0 MiB/99.1 MiB (84.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 57.2 MiB/99.1 MiB (84.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 57.5 MiB/99.1 MiB (84.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 57.8 MiB/99.1 MiB (84.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 58.0 MiB/99.1 MiB (84.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 58.2 MiB/99.1 MiB (84.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 58.5 MiB/99.1 MiB (84.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 58.8 MiB/99.1 MiB (84.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 59.0 MiB/99.1 MiB (84.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 59.2 MiB/99.1 MiB (84.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 59.5 MiB/99.1 MiB (85.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 59.8 MiB/99.1 MiB (85.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 60.0 MiB/99.1 MiB (85.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 60.2 MiB/99.1 MiB (85.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 60.5 MiB/99.1 MiB (85.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 60.8 MiB/99.1 MiB (85.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 61.0 MiB/99.1 MiB (86.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 61.2 MiB/99.1 MiB (85.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 61.5 MiB/99.1 MiB (85.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 61.8 MiB/99.1 MiB (85.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 62.0 MiB/99.1 MiB (86.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 62.2 MiB/99.1 MiB (86.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 62.5 MiB/99.1 MiB (86.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 62.8 MiB/99.1 MiB (86.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 63.0 MiB/99.1 MiB (86.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 63.2 MiB/99.1 MiB (86.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 63.5 MiB/99.1 MiB (86.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 63.8 MiB/99.1 MiB (86.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 64.0 MiB/99.1 MiB (87.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 64.2 MiB/99.1 MiB (87.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 64.5 MiB/99.1 MiB (87.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 64.8 MiB/99.1 MiB (86.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 65.0 MiB/99.1 MiB (86.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 65.2 MiB/99.1 MiB (87.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 65.5 MiB/99.1 MiB (87.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 65.8 MiB/99.1 MiB (87.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 66.0 MiB/99.1 MiB (87.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 66.2 MiB/99.1 MiB (87.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 66.5 MiB/99.1 MiB (87.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 66.8 MiB/99.1 MiB (87.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 67.0 MiB/99.1 MiB (87.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 67.2 MiB/99.1 MiB (88.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 67.5 MiB/99.1 MiB (87.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 67.8 MiB/99.1 MiB (88.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 68.0 MiB/99.1 MiB (88.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 68.2 MiB/99.1 MiB (88.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 68.5 MiB/99.1 MiB (87.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 68.8 MiB/99.1 MiB (87.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 69.0 MiB/99.1 MiB (87.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 69.2 MiB/99.1 MiB (88.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 69.5 MiB/99.1 MiB (87.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 69.8 MiB/99.1 MiB (88.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 70.0 MiB/99.1 MiB (88.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 70.2 MiB/99.1 MiB (88.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 70.5 MiB/99.1 MiB (88.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 70.8 MiB/99.1 MiB (88.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 71.0 MiB/99.1 MiB (88.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 71.2 MiB/99.1 MiB (88.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 71.5 MiB/99.1 MiB (88.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 71.8 MiB/99.1 MiB (89.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 72.0 MiB/99.1 MiB (89.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 72.2 MiB/99.1 MiB (89.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 72.5 MiB/99.1 MiB (89.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 72.8 MiB/99.1 MiB (89.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 73.0 MiB/99.1 MiB (89.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 73.2 MiB/99.1 MiB (89.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 73.5 MiB/99.1 MiB (89.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 73.8 MiB/99.1 MiB (89.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 74.0 MiB/99.1 MiB (89.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 74.2 MiB/99.1 MiB (89.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 74.5 MiB/99.1 MiB (88.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 74.8 MiB/99.1 MiB (89.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 75.0 MiB/99.1 MiB (89.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 75.2 MiB/99.1 MiB (89.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 75.5 MiB/99.1 MiB (89.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 75.8 MiB/99.1 MiB (89.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 76.0 MiB/99.1 MiB (89.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 76.2 MiB/99.1 MiB (89.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 76.5 MiB/99.1 MiB (89.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 76.8 MiB/99.1 MiB (89.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 77.0 MiB/99.1 MiB (89.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 77.2 MiB/99.1 MiB (89.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 77.5 MiB/99.1 MiB (89.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 77.8 MiB/99.1 MiB (89.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 78.0 MiB/99.1 MiB (90.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 78.2 MiB/99.1 MiB (90.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 78.5 MiB/99.1 MiB (89.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 78.8 MiB/99.1 MiB (90.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 79.0 MiB/99.1 MiB (89.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 79.2 MiB/99.1 MiB (90.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 79.5 MiB/99.1 MiB (89.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 79.8 MiB/99.1 MiB (90.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 80.0 MiB/99.1 MiB (90.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 80.2 MiB/99.1 MiB (90.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 80.5 MiB/99.1 MiB (90.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 80.8 MiB/99.1 MiB (90.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 81.0 MiB/99.1 MiB (90.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 81.2 MiB/99.1 MiB (90.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 81.5 MiB/99.1 MiB (90.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 81.8 MiB/99.1 MiB (90.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 82.0 MiB/99.1 MiB (90.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 82.2 MiB/99.1 MiB (90.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 82.5 MiB/99.1 MiB (90.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 82.8 MiB/99.1 MiB (90.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 83.0 MiB/99.1 MiB (90.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 83.2 MiB/99.1 MiB (90.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 83.5 MiB/99.1 MiB (90.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 83.8 MiB/99.1 MiB (90.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 84.0 MiB/99.1 MiB (90.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 84.2 MiB/99.1 MiB (90.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 84.5 MiB/99.1 MiB (90.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 84.8 MiB/99.1 MiB (90.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 85.0 MiB/99.1 MiB (90.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 85.2 MiB/99.1 MiB (91.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 85.5 MiB/99.1 MiB (91.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 85.8 MiB/99.1 MiB (91.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 86.0 MiB/99.1 MiB (91.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 86.2 MiB/99.1 MiB (91.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 86.5 MiB/99.1 MiB (91.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 86.8 MiB/99.1 MiB (91.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 87.0 MiB/99.1 MiB (91.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 87.2 MiB/99.1 MiB (91.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 87.5 MiB/99.1 MiB (91.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 87.8 MiB/99.1 MiB (91.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 88.0 MiB/99.1 MiB (91.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 88.2 MiB/99.1 MiB (91.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 88.5 MiB/99.1 MiB (91.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 88.8 MiB/99.1 MiB (91.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 89.0 MiB/99.1 MiB (91.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 89.2 MiB/99.1 MiB (91.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 89.5 MiB/99.1 MiB (91.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 89.8 MiB/99.1 MiB (92.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 90.0 MiB/99.1 MiB (91.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 90.2 MiB/99.1 MiB (91.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 90.5 MiB/99.1 MiB (91.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 90.8 MiB/99.1 MiB (91.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 91.0 MiB/99.1 MiB (91.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 91.2 MiB/99.1 MiB (91.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 91.5 MiB/99.1 MiB (92.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 91.8 MiB/99.1 MiB (91.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 92.0 MiB/99.1 MiB (92.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 92.2 MiB/99.1 MiB (92.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 92.5 MiB/99.1 MiB (92.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 92.8 MiB/99.1 MiB (92.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 93.0 MiB/99.1 MiB (92.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 93.2 MiB/99.1 MiB (92.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 93.5 MiB/99.1 MiB (92.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 93.8 MiB/99.1 MiB (92.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 93.8 MiB/99.1 MiB (92.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 94.1 MiB/99.1 MiB (92.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 94.3 MiB/99.1 MiB (92.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 94.6 MiB/99.1 MiB (92.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 94.8 MiB/99.1 MiB (92.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 95.1 MiB/99.1 MiB (91.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 95.3 MiB/99.1 MiB (91.1 MiB/s) with 1 file(s) remaining\r",
      "Completed 95.6 MiB/99.1 MiB (90.9 MiB/s) with 1 file(s) remaining\r",
      "Completed 95.8 MiB/99.1 MiB (90.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 96.1 MiB/99.1 MiB (90.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 96.3 MiB/99.1 MiB (90.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 96.6 MiB/99.1 MiB (90.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 96.8 MiB/99.1 MiB (89.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 97.1 MiB/99.1 MiB (89.6 MiB/s) with 1 file(s) remaining\r",
      "Completed 97.3 MiB/99.1 MiB (89.4 MiB/s) with 1 file(s) remaining\r",
      "Completed 97.6 MiB/99.1 MiB (89.2 MiB/s) with 1 file(s) remaining\r",
      "Completed 97.8 MiB/99.1 MiB (89.0 MiB/s) with 1 file(s) remaining\r",
      "Completed 98.1 MiB/99.1 MiB (88.8 MiB/s) with 1 file(s) remaining\r",
      "Completed 98.3 MiB/99.1 MiB (88.7 MiB/s) with 1 file(s) remaining\r",
      "Completed 98.6 MiB/99.1 MiB (88.5 MiB/s) with 1 file(s) remaining\r",
      "Completed 98.8 MiB/99.1 MiB (88.3 MiB/s) with 1 file(s) remaining\r",
      "Completed 99.1 MiB/99.1 MiB (88.1 MiB/s) with 1 file(s) remaining\r",
      "download: s3://sagemaker-sample-data-us-east-1/processing/census/census-income.csv to efs/ml/sagemaker_model/census-income.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘efs/ml/sagemaker_model’: File exists\n",
      "mkdir: cannot create directory ‘efs/ml/sagemaker_model/test’: File exists\n",
      "mkdir: cannot create directory ‘efs/ml/sagemaker_model/train’: File exists\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir efs/ml/sagemaker_model\n",
    "os.system(\"aws s3 cp {} efs/ml/sagemaker_model\".format(preprocessor))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now inspect the output of the pre-processing job, which consists of the processed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (10, 73)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.0.1</th>\n",
       "      <th>0.0.2</th>\n",
       "      <th>0.0.3</th>\n",
       "      <th>0.0.4</th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.0.5</th>\n",
       "      <th>0.0.6</th>\n",
       "      <th>0.0.7</th>\n",
       "      <th>0.0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0.56</th>\n",
       "      <th>0.0.57</th>\n",
       "      <th>0.0.58</th>\n",
       "      <th>0.0.59</th>\n",
       "      <th>0.0.60</th>\n",
       "      <th>1.0.4</th>\n",
       "      <th>0.0.61</th>\n",
       "      <th>0.0.62</th>\n",
       "      <th>0.0.63</th>\n",
       "      <th>0.0.64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0  0.0.1  0.0.2  0.0.3  0.0.4  1.0  0.0.5  0.0.6  0.0.7  0.0.8  ...  \\\n",
       "0  0.0    0.0    0.0    0.0    0.0  0.0    0.0    0.0    0.0    1.0  ...   \n",
       "1  0.0    0.0    0.0    0.0    0.0  1.0    0.0    0.0    0.0    0.0  ...   \n",
       "2  0.0    0.0    0.0    0.0    0.0  0.0    0.0    0.0    1.0    0.0  ...   \n",
       "3  0.0    0.0    1.0    0.0    0.0  0.0    0.0    0.0    0.0    0.0  ...   \n",
       "4  0.0    0.0    0.0    1.0    0.0  0.0    0.0    0.0    0.0    0.0  ...   \n",
       "5  0.0    0.0    0.0    0.0    0.0  0.0    0.0    1.0    0.0    0.0  ...   \n",
       "6  0.0    0.0    0.0    0.0    0.0  1.0    0.0    0.0    0.0    0.0  ...   \n",
       "7  0.0    0.0    0.0    0.0    0.0  0.0    1.0    0.0    0.0    0.0  ...   \n",
       "8  0.0    0.0    0.0    0.0    0.0  0.0    1.0    0.0    0.0    0.0  ...   \n",
       "9  1.0    0.0    0.0    0.0    0.0  0.0    0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "   0.0.56  0.0.57  0.0.58  0.0.59  0.0.60  1.0.4  0.0.61  0.0.62  0.0.63  \\\n",
       "0     0.0     0.0     0.0     0.0     1.0    0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0    1.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     1.0     0.0     0.0    0.0     0.0     0.0     0.0   \n",
       "3     0.0     0.0     0.0     0.0     0.0    1.0     0.0     0.0     0.0   \n",
       "4     0.0     0.0     0.0     0.0     0.0    0.0     1.0     0.0     0.0   \n",
       "5     0.0     0.0     0.0     0.0     0.0    0.0     1.0     0.0     0.0   \n",
       "6     0.0     0.0     0.0     0.0     0.0    1.0     0.0     0.0     0.0   \n",
       "7     0.0     0.0     0.0     0.0     0.0    1.0     0.0     0.0     0.0   \n",
       "8     0.0     0.0     0.0     0.0     0.0    1.0     0.0     0.0     0.0   \n",
       "9     1.0     0.0     0.0     0.0     0.0    1.0     0.0     0.0     0.0   \n",
       "\n",
       "   0.0.64  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "5     0.0  \n",
       "6     0.0  \n",
       "7     0.0  \n",
       "8     0.0  \n",
       "9     0.0  \n",
       "\n",
       "[10 rows x 73 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features = pd.read_csv(preprocessed_training_data + '/train_features.csv', nrows=10)\n",
    "print('Training features shape: {}'.format(training_features.shape))\n",
    "training_features.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using the pre-processed data\n",
    "\n",
    "We create a `SKLearn` instance, which we will use to run a training job using the training script `train.py`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point='train.py',\n",
    "    train_instance_type=\"ml.m5.xlarge\",\n",
    "    role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training script `train.py` trains a logistic regression model on the training data, and saves the model to the `/opt/ml/model` directory, which Amazon SageMaker tars and uploads into a `model.tar.gz` file into S3 at the end of the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    training_data_directory = '/opt/ml/input/data/train'\n",
    "    train_features_data = os.path.join(training_data_directory, 'train_features.csv')\n",
    "    train_labels_data = os.path.join(training_data_directory, 'train_labels.csv')\n",
    "    print('Reading input data')\n",
    "    X_train = pd.read_csv(train_features_data, header=None)\n",
    "    y_train = pd.read_csv(train_labels_data, header=None)\n",
    "\n",
    "    model = LogisticRegression(class_weight='balanced', solver='lbfgs')\n",
    "    print('Training LR model')\n",
    "    model.fit(X_train, y_train)\n",
    "    model_output_directory = os.path.join('/opt/ml/model', \"model.joblib\")\n",
    "    print('Saving model to {}'.format(model_output_directory))\n",
    "    joblib.dump(model, model_output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training job using `train.py` on the preprocessed training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.fit({'train': preprocessed_training_data})\n",
    "training_job_description = sklearn.jobs[-1].describe()\n",
    "model_data_s3_uri = '{}{}/{}'.format(\n",
    "    training_job_description['OutputDataConfig']['S3OutputPath'],\n",
    "    training_job_description['TrainingJobName'],\n",
    "    'output/model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"aws s3 cp {} efs/ml/sagemaker_model\".format(model_data_s3_uri))\n",
    "os.system(\"tar -xzf efs/ml/sagemaker_model/model.tar.gz --directory efs/ml/sagemaker_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sample Test Data For Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('mkdir test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('s3://sagemaker-sample-data-us-east-1/processing/census/census-income.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88215       50000+.\n",
       "94347       50000+.\n",
       "135917     - 50000.\n",
       "175569     - 50000.\n",
       "74772      - 50000.\n",
       "Name: income, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 =df.sample(5)\n",
    "df1['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df1).to_csv(\"test_data/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "aws s3 cp test_data/test_data.csv s3://lambdatestbucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>class of worker</th>\n",
       "      <th>detailed industry recode</th>\n",
       "      <th>detailed occupation recode</th>\n",
       "      <th>education</th>\n",
       "      <th>wage per hour</th>\n",
       "      <th>enroll in edu inst last wk</th>\n",
       "      <th>marital stat</th>\n",
       "      <th>major industry code</th>\n",
       "      <th>major occupation code</th>\n",
       "      <th>...</th>\n",
       "      <th>country of birth father</th>\n",
       "      <th>country of birth mother</th>\n",
       "      <th>country of birth self</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>own business or self employed</th>\n",
       "      <th>fill inc questionnaire for veteran's admin</th>\n",
       "      <th>veterans benefits</th>\n",
       "      <th>weeks worked in year</th>\n",
       "      <th>year</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Finance insurance and real estate</td>\n",
       "      <td>Sales</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>1</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>95</td>\n",
       "      <td>50000+.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>Private</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Manufacturing-nondurable goods</td>\n",
       "      <td>Executive admin and managerial</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>50000+.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Children</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>Bachelors degree(BA AB BS)</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Finance insurance and real estate</td>\n",
       "      <td>Executive admin and managerial</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>2</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>94</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Handlers equip cleaners etc</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>2</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>95</td>\n",
       "      <td>- 50000.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   class of worker  detailed industry recode  \\\n",
       "0   51           Private                        35   \n",
       "1   55           Private                        25   \n",
       "2    3   Not in universe                         0   \n",
       "3   31           Private                        34   \n",
       "4   28           Private                         4   \n",
       "\n",
       "   detailed occupation recode                    education  wage per hour  \\\n",
       "0                          17   Some college but no degree              0   \n",
       "1                           3         High school graduate              0   \n",
       "2                           0                     Children              0   \n",
       "3                           2   Bachelors degree(BA AB BS)              0   \n",
       "4                          40         High school graduate              0   \n",
       "\n",
       "  enroll in edu inst last wk                      marital stat  \\\n",
       "0            Not in universe   Married-civilian spouse present   \n",
       "1            Not in universe   Married-civilian spouse present   \n",
       "2            Not in universe                     Never married   \n",
       "3            Not in universe   Married-civilian spouse present   \n",
       "4            Not in universe   Married-civilian spouse present   \n",
       "\n",
       "                  major industry code            major occupation code  ...  \\\n",
       "0   Finance insurance and real estate                            Sales  ...   \n",
       "1      Manufacturing-nondurable goods   Executive admin and managerial  ...   \n",
       "2         Not in universe or children                  Not in universe  ...   \n",
       "3   Finance insurance and real estate   Executive admin and managerial  ...   \n",
       "4                        Construction     Handlers equip cleaners etc   ...   \n",
       "\n",
       "  country of birth father country of birth mother country of birth self  \\\n",
       "0           United-States           United-States         United-States   \n",
       "1           United-States           United-States         United-States   \n",
       "2           United-States           United-States         United-States   \n",
       "3           United-States           United-States         United-States   \n",
       "4           United-States           United-States         United-States   \n",
       "\n",
       "                          citizenship own business or self employed  \\\n",
       "0   Native- Born in the United States                             1   \n",
       "1   Native- Born in the United States                             0   \n",
       "2   Native- Born in the United States                             0   \n",
       "3   Native- Born in the United States                             2   \n",
       "4   Native- Born in the United States                             2   \n",
       "\n",
       "  fill inc questionnaire for veteran's admin  veterans benefits  \\\n",
       "0                            Not in universe                  2   \n",
       "1                            Not in universe                  2   \n",
       "2                            Not in universe                  0   \n",
       "3                            Not in universe                  2   \n",
       "4                            Not in universe                  2   \n",
       "\n",
       "   weeks worked in year  year     income  \n",
       "0                    52    95    50000+.  \n",
       "1                    52    94    50000+.  \n",
       "2                     0    94   - 50000.  \n",
       "3                    51    94   - 50000.  \n",
       "4                    14    95   - 50000.  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"s3://lambdatestbucket/test_data.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor Loaded\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.20.0 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import tarfile\n",
    "from pickle import load\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "\n",
    "model_path = os.path.join('efs/ml/sagemaker_model', 'model.joblib')\n",
    "preprocessor_path = os.path.join('efs/ml/sagemaker_model','preprocessor.pkl' )\n",
    "preprocessor = load(open(preprocessor_path, 'rb'))\n",
    "print(\"Preprocessor Loaded\")\n",
    "\n",
    "print('Loading model')\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'education', 'major industry code', 'class of worker', 'num persons worked for employer',\n",
    "       'capital gains', 'capital losses', 'dividends from stocks', 'income']\n",
    "class_labels = [' - 50000.', ' 50000+.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test input data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>major industry code</th>\n",
       "      <th>class of worker</th>\n",
       "      <th>num persons worked for employer</th>\n",
       "      <th>capital gains</th>\n",
       "      <th>capital losses</th>\n",
       "      <th>dividends from stocks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>Finance insurance and real estate</td>\n",
       "      <td>Private</td>\n",
       "      <td>6</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>Manufacturing-nondurable goods</td>\n",
       "      <td>Private</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Children</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>Bachelors degree(BA AB BS)</td>\n",
       "      <td>Finance insurance and real estate</td>\n",
       "      <td>Private</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Private</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                    education                 major industry code  \\\n",
       "0   51   Some college but no degree   Finance insurance and real estate   \n",
       "1   55         High school graduate      Manufacturing-nondurable goods   \n",
       "2    3                     Children         Not in universe or children   \n",
       "3   31   Bachelors degree(BA AB BS)   Finance insurance and real estate   \n",
       "4   28         High school graduate                        Construction   \n",
       "\n",
       "    class of worker  num persons worked for employer  capital gains  \\\n",
       "0           Private                                6           5178   \n",
       "1           Private                                6              0   \n",
       "2   Not in universe                                0              0   \n",
       "3           Private                                2              0   \n",
       "4           Private                                4              0   \n",
       "\n",
       "   capital losses  dividends from stocks  \n",
       "0               0                      0  \n",
       "1               0                    175  \n",
       "2               0                      0  \n",
       "3               0                      0  \n",
       "4               0                      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Loading test input data')\n",
    "test_data = \"test_data/test_data.csv\"\n",
    "df = pd.read_csv(test_data)\n",
    "df = pd.DataFrame(data=df, columns=columns)\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.replace(class_labels, [0, 1], inplace=True)\n",
    "X_test = df.drop('income', axis=1)\n",
    "y_test = df['income']\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running preprocessing and feature engineering transformations\n",
      "Saving test features to test_data/test_features.csv\n",
      "Saving test labels to test_data/test_labels.csv\n"
     ]
    }
   ],
   "source": [
    "print('Running preprocessing and feature engineering transformations')\n",
    "test_features = preprocessor.transform(X_test)\n",
    "\n",
    "test_features_output_path = os.path.join('test_data', 'test_features.csv')  \n",
    "test_labels_output_path = os.path.join('test_data', 'test_labels.csv')\n",
    "\n",
    "print('Saving test features to {}'.format(test_features_output_path))\n",
    "pd.DataFrame(test_features).to_csv(test_features_output_path, header=False, index=False)\n",
    "\n",
    "print('Saving test labels to {}'.format(test_labels_output_path))\n",
    "y_test.to_csv(test_labels_output_path, header=False, index=False)\n",
    "    \n",
    "X_test = pd.read_csv(test_features_output_path, header=None)\n",
    "actual_values = pd.read_csv(test_labels_output_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.replace([0,1], [\"Less than 50K\", \"Greater than 50K\"], inplace=True)\n",
    "actual_values.replace([0,1], [\"Less than 50K\", \"Greater than 50K\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greater than 50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greater than 50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Less than 50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Less than 50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Less than 50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "0  Greater than 50K\n",
       "1  Greater than 50K\n",
       "2     Less than 50K\n",
       "3     Less than 50K\n",
       "4     Less than 50K"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Actual Values:\")\n",
    "actual_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predicitons:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greater than 50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Less than 50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Less than 50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greater than 50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Less than 50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "0  Greater than 50K\n",
       "1     Less than 50K\n",
       "2     Less than 50K\n",
       "3  Greater than 50K\n",
       "4     Less than 50K"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Model Predicitons:\")\n",
    "predictions_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
